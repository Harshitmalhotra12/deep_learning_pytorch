{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    A typical training procedure for a neural network is as follows:\n",
    "\n",
    "        - Define the neural network that has some learnable parameters (or weights)\n",
    "        - Iterate over a dataset of inputs\n",
    "        - Process input through the network\n",
    "        - Compute the loss (how far is the output from being correct)\n",
    "        - Propagate gradients back into the networkâ€™s parameters\n",
    "        - Update the weights of the network, typically using a simple update rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Neural Network\n",
    "![Neural Network](img/Perceptron.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<video controls src=\"img/Neural.webm\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=40, out_features=32, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (7): ReLU()\n",
      "  (8): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (9): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net =   nn.Sequential(\n",
    "        nn.Linear(40, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, 16),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(16, 8),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(8, 4),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4, 1),\n",
    "        nn.Tanh()\n",
    "    )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "        weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(40, 40)\n",
    "y = torch.randn(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40])\n",
      "tensor(1.2338, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2336, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2335, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2334, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2332, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2331, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2329, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2328, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2326, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2325, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2323, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2322, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2321, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2319, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2318, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2316, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2315, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2313, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2312, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2310, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2309, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2308, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2306, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2305, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2303, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2302, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2300, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2299, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2297, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2296, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2295, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2293, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2292, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2290, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2289, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2287, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2286, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2284, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2283, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2282, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2280, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2279, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2277, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2276, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2274, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2273, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2272, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2270, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2269, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2267, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2266, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2264, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2263, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2261, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2260, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2259, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2257, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2256, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2254, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2253, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2251, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2250, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2249, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2247, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2246, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2244, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2243, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2241, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2240, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2239, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2237, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2236, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2234, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2233, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2231, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2230, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2229, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2227, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2226, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2224, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2223, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2221, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2220, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2219, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2217, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2216, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2214, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2213, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2211, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2210, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2209, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2207, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2206, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2204, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2203, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2201, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2200, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2199, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2197, grad_fn=<MseLossBackward>)\n",
      "torch.Size([40])\n",
      "tensor(1.2196, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for t in range(100):\n",
    "    out = net(x)                 # input x and predict based on x\n",
    "    print(y.size())\n",
    "    loss = loss_fn(out, y)     # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
